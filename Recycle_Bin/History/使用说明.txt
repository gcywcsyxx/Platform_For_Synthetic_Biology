数据准备：在Raw_Comment文件中，导入任意自然语言数据，比如问卷中某一列的文字或者大段文字，程序会自动分析
1、使用前需要在电脑命令行下载五个python库 ：
re
pandas
matplotlib
jieba
collections
wordcloud
示例：pip  install pandas
具体可以到网址
https://pypi.org/
去搜索 获取最新版本对应的名称（这个一定要按照官网上的名称来输入）
2、使用某个IDE（推荐VS code或Pycharm）打开abc.py文件
3、代码中对应位置可以修改导入tif格式的字体（默认是微软雅黑）
4、运行程序，可见前100高频词汇和标准云图
5、具体参数可以根据需要自行调整（如高频词个数、常用语列表词汇、云图颜色、形状等

批量化下载Python模块好方法：首先利用-i来调用国内镜像；其次用-r来调用需要所需要的模块即可！
例如：
pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple -r /home/gcy/下载/python结巴分词+云图绘制/modules.txt

在txt文件中有明确的可以下载的模块 好几个 一行一个


一个自己想的算法：实现搜索引擎输入几个词语 检索同时具有的情况（评论）
1、结巴统计词频 选出前20名作为第一个树的第一分叉
2、抽取前二十的词语 进行文本匹配 筛选出很多堆带有这个词语的文本集
3、每个文本集分别统计词频 除去第一层的词语 再排个词频率高低并取前几名作为第二分叉
4、在第二分叉循环往复 生成新的分叉 而且会在树的每个节点标注出词频
5、这样搜索引擎便可以实现几个词语空格隔开  然后依然可以搜索到了